# -*- coding: utf-8 -*-
"""Решение 4 задачи.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KYv4gFxp9dIZB5dcB2g5XAu7hoGR71A4
"""

from google.colab import files
uploaded = files.upload()

# иморитирование всех необходимых библиотек
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Считываем тренировочные данные
train = pd.read_csv("train_oil.csv")

print(f"Train dataset shape: {train.shape}")

# Считываем тестовые данные
test = pd.read_csv("oil_test.csv")

print(f"Test dataset shape: {test.shape}")

train['Onshore/Offshore'].value_counts()

"""## Предобработка данных

### Тренировочный набора данных
"""

train = train.drop(columns=['Country', 'Basin name', 'Region', 'Longitude', 'Latitude'])

train.isna().sum()

train.head()

tmp = train.copy()
tmp = tmp['Tectonic regime'].str.get_dummies('/').add_prefix('regime_').reset_index(drop=True)
tmp.head()

tmp.shape

train_full = pd.concat([train, tmp], axis=1)
train_full

tmp = train.copy()
tmp = tmp['Structural setting'].str.get_dummies('/').add_prefix('Structural setting_').reset_index(drop=True)
train_full = pd.concat([train_full, tmp], axis=1)
train_full

train_full = pd.get_dummies(train_full, columns=['Hydrocarbon type', 'Reservoir status', 'Reservoir period', 'Lithology'])

train_full.drop(['Tectonic regime'], axis=1, inplace=True)
train_full.drop(['Structural setting'], axis=1, inplace=True)
train_full.shape

train_full = train_full.drop(columns=['Field name', 'Reservoir unit', 'Operator company'])
train_full.shape

from sklearn import preprocessing

le = preprocessing.LabelEncoder()
train_full['Onshore/Offshore'] = le.fit_transform(train_full['Onshore/Offshore'])

train_full.loc[:, train_full.dtypes == object].columns

mapping = dict(zip(le.classes_, range(len(le.classes_))))
mapping

"""### Тестовый набор данных"""

#test = test.drop(columns=['Country', 'Basin name', 'Region', 'Longitude', 'Latitude'])
test.isna().sum()

tmp = test.copy()
tmp = tmp['Tectonic regime'].str.get_dummies('/').add_prefix('regime_').reset_index(drop=True)
test_full = pd.concat([test, tmp], axis=1)

tmp = test.copy()
tmp = tmp['Structural setting'].str.get_dummies('/').add_prefix('Structural setting_').reset_index(drop=True)
test_full = pd.concat([test_full, tmp], axis=1)

test_full = pd.get_dummies(test_full, columns=['Hydrocarbon type', 'Reservoir status', 'Reservoir period', 'Lithology'])

test_full.drop(['Tectonic regime'], axis=1, inplace=True)
test_full.drop(['Structural setting'], axis=1, inplace=True)
test_full.shape

test_full = test_full.drop(columns=['Field name', 'Reservoir unit', 'Operator company'])
test_full.shape

train_col = train_full.columns
test_col = test_full.columns
cols_int = set(train_col) & set(test_col)
len(cols_int)

cols_int

y = train_full['Onshore/Offshore']
train_full = train_full[cols_int]
test_full = test_full[cols_int]

print(train_full.shape)
print(test_full.shape)

corr = train_full.corr()

correlated_features = set()

for i in range(len(corr.columns)):
    for j in range(i):
        if abs(corr.iloc[i, j]) > 0.8:
            colname = corr.columns[i]
            correlated_features.add(colname)

correlated_features

train_full.drop(columns=['regime_BASEMENT-I'], inplace=True)
test_full.drop(columns=['regime_BASEMENT-I'], inplace=True)

print(test_full.shape)
print(train_full.shape)

X = train_full.copy()

print(X.shape) 
print(y.shape)

"""## Обучение модели"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

print(f'Train dataset size: {X_train.shape}, {y_train.shape}')
print(f'Train dataset size: {X_test.shape}, {y_test.shape}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import accuracy_score
# 
# clf = RandomForestClassifier(n_estimators=100, random_state=42)
# 
# clf.fit(X_train, y_train)
# y_pred = clf.predict(X_test)
# 
# print(accuracy_score(y_test, y_pred))

importances = clf.feature_importances_

forest_importances = pd.Series(importances, index=X.columns)

forest_importances = forest_importances.sort_values()

plt.figure(figsize=(10,10))
forest_importances.plot(kind='barh')
plt.show()

len(forest_importances[forest_importances > 0.0011181362767552299])

train_full = train_full[forest_importances[forest_importances > 0.0011181362767552299].index]
test_full = test_full[forest_importances[forest_importances > 0.0011181362767552299].index]

X = train_full.copy()

print(X.shape) 
print(y.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

print(f'Train dataset size: {X_train.shape}, {y_train.shape}')
print(f'Train dataset size: {X_test.shape}, {y_test.shape}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import accuracy_score
# 
# clf = RandomForestClassifier(n_estimators=100, random_state=42)
# 
# clf.fit(X_train, y_train)
# y_pred = clf.predict(X_test)
# 
# print(accuracy_score(y_test, y_pred))

mapping

inv_map = {v: k for k, v in mapping.items()}
inv_map

y_test_pred = clf.predict(test_full)

y_pred_test = pd.DataFrame(y_test_pred, columns=['Onshore/Offshore'])
y_pred_test = y_pred_test.reset_index()

y_pred_test['Onshore/Offshore'] = y_pred_test['Onshore/Offshore'].map(inv_map).fillna(y_pred_test['Onshore/Offshore'])

y_pred_test.to_csv("solution.csv", index=False)

files.download("solution.csv")